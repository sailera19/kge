job.type: train
dataset.name: wnrr

import: [transformer]
model: reciprocal_relations_model
reciprocal_relations_model.base_model:
  type: transformer


  tokenization:
    trainer:
      min_frequency: 3
  enable_text: False
  entity_embedder:
    type: text_transformer_embedder
    tokenization:
      trainer:
        min_frequency: 3
    initialize: normal_
    dim: 80
    dropout: 0.6
    encoder:
      dropout: 0.6

train:
  optimizer: Adam
  optimizer_args:
    lr: 0.001
  batch_size: 512
  max_epochs: 500
  loss: kl
  type: negative_sampling
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_args:
    mode: max
    patience: 2
    factor: 0.5
  lr_warmup: 50

negative_sampling:
  shared: True
  with_replacement: False
  implementation: batch
  num_samples:
    s: 2048

transformer:
  entity_embedder:
    initialize: xavier_normal_
    dim: 80
    dropout: 0.6
  relation_embedder:
    initialize: xavier_normal_
    dim: 80
    dropout: 0.6
  text_embedder:
    initialize: xavier_normal_
    dim: 320
    dropout: 0.6

valid:
  early_stopping:
    patience: 5
  every: 5
  metric: mean_reciprocal_rank_filtered_with_test

#eval.batch_size: 1024
eval.batch_size: 100000
entity_ranking.chunk_size: 128