# wnrr-conve-1vsAll-kl
job.type: search
search.type: ax
dataset.name: wnrr

# training settings (fixed)
train:
  max_epochs: 400
  auto_correct: True

# this is faster for smaller datasets, but does not work for some models (e.g.,
# TransE due to a pytorch issue) or for larger datasets. Change to spo in such
# cases (either here or in ax section of model config), results will not be
# affected.
negative_sampling.implementation: sp_po

# validation/evaluation settings (fixed)
valid:
  every: 5
  metric: mean_reciprocal_rank_filtered_with_test
  filter_with_test: True
  early_stopping:
    patience: 10
    min_threshold.epochs: 50
    min_threshold.metric_value: 0.15

eval:
  batch_size: 1024
  metrics_per.relation_type: True

# settings for reciprocal relations (if used)
import: [conve, reciprocal_relations_model]
reciprocal_relations_model.base_model.type: conve

# ax settings: hyperparameter serach space
ax_search:
  num_trials: 30
  num_sobol_trials: 30 # differs in the files
  parameters:
      # model
    - name: model
      type: fixed
      value: reciprocal_relations_model

    # training hyperparameters
    - name: train.batch_size
      type: choice
      values: [128, 256, 512, 1024] #1024 hardly possible on one GPU without subbatches
      is_ordered: True
    - name: train.type
      type: fixed
      value: 1vsAll
    - name: train.optimizer
      type: choice
      values: [Adam, Adagrad] # try if adamax and adam equal in memory usage
    - name: train.loss
      type: fixed
      value: kl # loss_arg? HittER paper used label smoothing for KL in wnrr
    - name: train.loss_arg
      type: range
      bounds: [-0.1, 1.0] # loss_arg? HittER paper used label smoothing for KL in wnrr
      log_scale: True # ask
    - name: train.optimizer_args.lr
      type: range
      bounds: [0.0003, 1.0]
      log_scale: True
    - name: train.lr_scheduler
      type: fixed
      value: LinearLR # try reduceonplateau
    - name: train.lr_scheduler_args.start_factor
      type: fixed
      value: 1
    - name: train.lr_scheduler_args.end_factor
      type: fixed
      value: 0
    - name: train.lr_scheduler_args.total_iters
      type: fixed
      value: 450 # what is intended max epochs?
    - name: train.lr_warmup
      type: fixed
      bounds: 50

    # embedding dimension
    - name: lookup_embedder.dim
      type: choice
      values: [128, 256, 320] # 512 hardly possible on one GPU, include 320 as the original proposed?
      is_ordered: True

    # embedding initialization
    - name: lookup_embedder.initialize
      type: choice
      values: [xavier_normal_, xavier_uniform_, normal_, uniform_]
    - name: lookup_embedder.initialize_args.normal_.mean
      type: fixed
      value: 0.0
    - name: lookup_embedder.initialize_args.normal_.std
      type: range
      bounds: [0.00001, 1.0]
      log_scale: True
    - name: lookup_embedder.initialize_args.uniform_.a
      type: range
      bounds: [-1.0, -0.00001]
    - name: lookup_embedder.initialize_args.xavier_uniform_.gain
      type: fixed
      value: 1.0
    - name: lookup_embedder.initialize_args.xavier_normal_.gain
      type: fixed
      value: 1.0

    # embedding regularization
    - name: lookup_embedder.regularize
      type: choice
      values: ['', 'l3', 'l2', 'l1']
      is_ordered: True
    - name: lookup_embedder.regularize_args.weighted
      type: choice
      values: [True, False]
    - name: hitter.entity_embedder.regularize_weight
      type: range
      bounds: [1.0e-20, 1.0e-01]
      log_scale: True
    - name: hitter.relation_embedder.regularize_weight
      type: range
      bounds: [1.0e-20, 1.0e-01]
      log_scale: True

    # embedding dropout
    # using using output_dropout instead as the model does the dropout
    # another time between the transformers
    # why negative?
    # 0.8
    - name: hitter.output_dropout
      type: range
      bounds: [0.0, 0.8]

    # training-type specific hyperparameters
    # model-specific entries
    - name: hitter.neighborhood_size
      type: fixed #?
      value: 12

    - name: hitter.implementation
      type: fixed
      value: pytorch

    - name: hitter.layer_norm_implmentation
      type: fixed
      value: pytorch

    - name: hitter.drop_neighborhood_fraction
      type: range
      bounds: [0.0, 0.8]

    - name: hitter.entity_dropout
      type: range
      bounds: [0.0, 1.0]

    - name: hitter.entity_dropout_masked
      type: range
      bounds: [0.0, 0.8]

    - name: hitter.entity_dropout_replaced
      type: range
      bounds: [0.0, 0.8]

    - name: hitter.add_mlm_loss
      type: choice
      values: [True, False]
